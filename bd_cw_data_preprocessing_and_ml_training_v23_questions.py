# -*- coding: utf-8 -*-
"""BD-CW Data preprocessing and ML training v23 - Questions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16P_PNPhKFXWB78P3mWZPZ0vsBGIJaunp

# Big Data Coursework - Questions

## Data Processing and Machine Learning in the Cloud 

This is the **INM432 Big Data coursework 2023**. 
This coursework contains extended elements of **theory** and **practice**, mainly around parallelisation of tasks withSpark and a bit about parallel training using TensorFlow.   

## Code and Report

Your tasks parallelization of tasks in PySpark, extension, evaluation, and theoretical reflection. 
Please complete and submit the **coding tasks** in a copy of **this notebook**. 
Write your code in the **indicated cells** and **include** the **output** in the submitted notebook.  
Make sure that **your code contains comments** on its **stucture** and explanations of its **purpose**. 

Provide also a **report** with the **textual answers in a separate document**.  
Include **screenshots** from the Google Cloud web interface (don't use the SCREENSHOT function that Google provides, but take a picture of the graphs you see for the VMs) and result tables, as well as written text about the analysis. 

## Submission

Download and submit **your version of this notebook** as an **.ipynb** file and also submit a **shareable link** to your notebook on Colab in your report (created with the Colab 'Share' function) (**and don’t change the online version after submission**). 

Further, provide your **report as a PDF document**. **State the number of words** in the document at the end. The report should **not have more than 2000 words**.

## Introduction and Description

This coursework focuses on parallelisation and scalability in the cloud with Spark and TesorFlow/Keras. 
We start with code based on **lessons 3 and 4** of the [*Fast and Lean Data Science*](https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/fast-and-lean-data-science) course by Martin Gorner. 
The course is based on Tensorflow for data processing and MachineLearning. 
Tensorflow's data processing approach is somewhat similar to that of Spark, but you don't need to study Tensorflow, just make sure you understand the high-level structure.  
What we will do here is **parallelising** **pre-processing**, and **measuring** performance, and we will perform **evaluation** and **analysis** on the cloud performance, as well as **theoretical discussion**. 

This coursework contains **3 sections**. 

### Section 0

This section just contains some necessary code for setting up the environment. It has no tasks for you (but do read the code and comments). 

### Section 1 
Section 1 is about preprocessing a set of image files.
We will work with a public dataset “Flowers” (3600 images, 5 classes). 
This is not a vast dataset, but it keeps the tasks more manageable for development and you can scale up later, if you like. 

In **'Getting Started'** we will work through the data preprocessing code from *Fast and Lean Data Science* which uses TensorFlow's `tf.data` package. 
There is no task for you here, but you will need to re-use some of this code later. 

In **Task 1** you will **parallelise the data preprocessing in Spark**, using Google Cloud (GC) Dataproc. 
This involves adapting the code from 'Getting Started' to use Spark and running it in the cloud. 

### Section 2 
In **Section 2** we are going to **measure the speed of reading data** in the cloud. In **Task  2** we will **paralellize the measuring** of different configurations **using Spark**.

### Section 3

This section is about the theoretical discussion, based on one paper, in **Task 3**. The answers should be given in the PDF report. 

### General points

For **all coding tasks**, take the **time of the operations** and for the cloud operations, get performance **information from the web interfaces** for your reporting and analysis. 

The **tasks** are **mostly independent** of each other. The later tasks can mostly be addressed without needing the solution to the earlier ones.

# Section 0: Set-up

As usual, you need to run the **imports and authentication every time you work with this notebook**. Use the **local Spark** installation for development before you send jobs to the cloud. 

Read through this section once and **fill in the project ID the first time**, then you can just step straight throught this at the beginning of each session - except for the two authentication cells.

### Imports

We import some **packages that will be needed throughout**. 
For the **code that runs in the cloud**, we will need **separate import sections** that will need to be partly different from the one below.
"""

import os, sys, math
import numpy as np
import scipy as sp
import scipy.stats
import time
import datetime
import string
import random
from matplotlib import pyplot as plt
import tensorflow as tf
print("Tensorflow version " + tf.__version__)
import pickle

"""### Cloud and Drive authentication

This is for **authenticating with with GCS Google Drive**, so that we can create and use our own buckets and access Dataproc and AI-Platform. 

This section **starts with the two interactive authentications**.

First, we mount Google Drive for persistent local storage and create a directory `DB-CW` thay you can use for this work. 
Then we'll set up the cloud environment, including a storage bucket.
"""

# Commented out IPython magic to ensure Python compatibility.
print('Mounting google drive...')
from google.colab import drive
drive.mount('/content/drive')
# %cd "/content/drive/MyDrive"
!mkdir BD-CW
# %cd "/content/drive/MyDrive/BD-CW"

"""Next, we authenticate with the GCS to enable access to Dataproc and AI-Platform."""

import sys
if 'google.colab' in sys.modules:
    from google.colab import auth
    auth.authenticate_user()

"""It is useful to **create a new Google Cloud project** for this coursework. You can do this on the [GC Console page](https://console.cloud.google.com) by clicking on the entry at the top, right of the *Google Cloud Platform* and choosing *New Project*. **Copy** the **generated project ID** to the next cell. Also **enable billing** and the **Compute, Storage and Dataproc** APIs like we did during the labs.

We also specify the **default project and region**. The REGION should be `us-central1` as that seems to be the only one that reliably works with the free credit. 
This way we don't have to specify this information every time we access the cloud.  
"""

PROJECT = 'big-data-cw22-344415'  ### USE YOUR GOOGLE CLOUD PROJECT ID HERE. ### 
!gcloud config set project $PROJECT
REGION = 'us-central1'
CLUSTER = '{}-cluster'.format(PROJECT)
!gcloud config set compute/region $REGION
!gcloud config set dataproc/region $REGION

!gcloud config list # show some information

"""With the cell below, we **create a storage bucket** that we will use later for **global storage**. 
If the bucket exists you will see a "ServiceException: 409 ...", which does not cause any problems. 
**You must create your own bucket to have write access.**
"""

BUCKET = 'gs://{}-storage'.format(PROJECT)
!gsutil mb $BUCKET

"""The cell below just **defines some routines for displaying images** that will be **used later**. You can see the code by double-clicking, but you don't need to study this."""

#@title Utility functions for image display **[RUN THIS TO ACTIVATE]** { display-mode: "form" }
def display_9_images_from_dataset(dataset):
  plt.figure(figsize=(13,13))
  subplot=331
  for i, (image, label) in enumerate(dataset):
    plt.subplot(subplot)
    plt.axis('off')
    plt.imshow(image.numpy().astype(np.uint8))   
    plt.title(str(label.numpy()), fontsize=16)
    # plt.title(label.numpy().decode(), fontsize=16)
    subplot += 1
    if i==8:
      break
  plt.tight_layout()
  plt.subplots_adjust(wspace=0.1, hspace=0.1)
  plt.show()

def display_training_curves(training, validation, title, subplot):
  if subplot%10==1: # set up the subplots on the first call
    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')
    plt.tight_layout()
  ax = plt.subplot(subplot)
  ax.set_facecolor('#F8F8F8')
  ax.plot(training)
  ax.plot(validation)
  ax.set_title('model '+ title)
  ax.set_ylabel(title)
  ax.set_xlabel('epoch')
  ax.legend(['train', 'valid.'])

def dataset_to_numpy_util(dataset, N):
    dataset = dataset.batch(N)
    for images, labels in dataset:
        numpy_images = images.numpy()
        numpy_labels = labels.numpy()
        break;
    return numpy_images, numpy_labels

def title_from_label_and_target(label, correct_label):
  correct = (label == correct_label)
  return "{} [{}{}{}]".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',
                              CLASSES[correct_label] if not correct else ''), correct

def display_one_flower(image, title, subplot, red=False):
    plt.subplot(subplot)
    plt.axis('off')
    plt.imshow(image)
    plt.title(title, fontsize=16, color='red' if red else 'black')
    return subplot+1

def display_9_images_with_predictions(images, predictions, labels):
  subplot=331
  plt.figure(figsize=(13,13))
  classes = np.argmax(predictions, axis=-1)
  for i, image in enumerate(images):
    title, correct = title_from_label_and_target(classes[i], labels[i])
    subplot = display_one_flower(image, title, subplot, not correct)
    if i >= 8:
      break;
              
  plt.tight_layout()
  plt.subplots_adjust(wspace=0.1, hspace=0.1)
  plt.show()

"""### Install Spark locally for quick testing 

You can use the cell below to **install Spark locally on this Colab VM** (like in the labs), to do quicker small-scale interactive testing. Using Spark in the cloud with **Dataproc is still required for the final version**. 

"""

# Commented out IPython magic to ensure Python compatibility.
# %cd
!apt-get update -qq
!apt-get install openjdk-8-jdk-headless -qq >> /dev/null # send any output to null device
!tar -xzf "/content/drive/My Drive/Big_Data/data/spark/spark-3.2.0-bin-hadoop2.7.tgz" # unpack 

!pip install -q findspark
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/root/spark-3.2.0-bin-hadoop2.7"
import findspark
findspark.init()
import pyspark
print(pyspark.__version__)
sc = pyspark.SparkContext.getOrCreate()
print(sc)

"""# Section 1: Data pre-processing

This section is about the **pre-processing of a dataset** for deep learning. 
We first look at a ready-made solution using Tensorflow and then we build a implement the same process with Spark. 
The tasks are about **parallelisation** and **analysis** the performance of the cloud implementations.

## 1.1 Getting started 

In this section, we get started with the data pre-processing. The code is based on lecture 3 of the 'Fast and Lean Data Science' course.

**This code is using the TensorFlow** `tf.data` package, which supports map functions, similar to Spark. Your **task** will be to **re-implement the same approach in Spark**.

We start by **setting some variables for the *Flowers* dataset**.
"""

GCS_PATTERN = 'gs://flowers-public/*/*.jpg' # glob  pattern for input files
PARTITIONS = 16 # no of partitions we will use later 
TARGET_SIZE = [192, 192] # target resolution for the images
CLASSES = [b'daisy', b'dandelion', b'roses', b'sunflowers', b'tulips']
    # labels for the data

"""We **read the image files** from the public GCS bucket that contains the *Flowers* dataset. 
**TensorFlow** has **functions** to execute glob patterns that we use to calculate the the number of images in total and per partition (rounded up as we cannont deal with parts of images).
"""

nb_images = len(tf.io.gfile.glob(GCS_PATTERN)) # number of images
partition_size = math.ceil(1.0 * nb_images / PARTITIONS) # images per partition (float)
print("GCS_PATTERN matches {} images, to be divided into {} partitions with up to {} images each.".format(nb_images, PARTITIONS, partition_size))

"""### Map functions

In order to read use the images for learning, they need to be **preprocessed** (decoded, resized, cropped, and potentially recompressed). 
Below are **map functions** for these steps. 
You **don't need to study** the **internals of these functions** in detail. 
"""

def decode_jpeg_and_label(filepath):
    # extracts the image data and creates a class label, based on the filepath 
    bits = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(bits)
    # parse flower name from containing directory
    label = tf.strings.split(tf.expand_dims(filepath, axis=-1), sep='/')
    label2 = label.values[-2]
    return image, label2

def resize_and_crop_image(image, label):
    # Resizes and cropd using "fill" algorithm:
    # always make sure the resulting image is cut out from the source image 
    # so that it fills the TARGET_SIZE entirely with no black bars 
    # and a preserved aspect ratio.
    w = tf.shape(image)[0]
    h = tf.shape(image)[1]
    tw = TARGET_SIZE[1]
    th = TARGET_SIZE[0]
    resize_crit = (w * th) / (h * tw)
    image = tf.cond(resize_crit < 1,
                    lambda: tf.image.resize(image, [w*tw/w, h*tw/w]), # if true
                    lambda: tf.image.resize(image, [w*th/h, h*th/h])  # if false
                    )
    nw = tf.shape(image)[0]
    nh = tf.shape(image)[1]
    image = tf.image.crop_to_bounding_box(image, (nw - tw) // 2, (nh - th) // 2, tw, th)
    return image, label

def recompress_image(image, label):
    # this reduces the amount of data, but takes some time
    image = tf.cast(image, tf.uint8)
    image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)
    return image, label

"""With `tf.data`, we can apply decoding and resizing as map functions."""

dsetFiles = tf.data.Dataset.list_files(GCS_PATTERN) # This also shuffles the images
dsetDecoded = dsetFiles.map(decode_jpeg_and_label)
dsetResized = dsetDecoded.map(resize_and_crop_image)

"""We can also look at some images using the image display function defined above (the one with the hidden code)."""

display_9_images_from_dataset(dsetResized)

"""Now, let's test continuous reading from the dataset. We can see that reading the first 100 files already takes some time."""

sample_set = dsetResized.batch(10).take(10) # take 10 batches of 10 images for testing
for image, label in sample_set: 
    print("Image batch shape {}, {})".format(image.numpy().shape,
        [lbl.decode('utf8') for lbl in label.numpy()]))

"""## 1.2 Improving Speed 

Using individual image files didn't look very fast. The 'Lean and Fast Data Science' course introduced **two techniques to improve the speed**.

### Recompress the images
By **compressing** the images in the **reduced resolution** we save on the size. 
This **costs some CPU time** upfront, but **saves network and disk bandwith**, especially when the data are **read multiple times**.
"""

# This is a quick test to get an idea how long recompressions takes.  
dataset4 = dsetResized.map(recompress_image)
test_set = dataset4.batch(10).take(10)
for image, label in test_set:
    print("Image batch shape {}, {})".format(image.numpy().shape, [lbl.decode('utf8') for lbl in label.numpy()]))

"""### Write the dataset to TFRecord files

By writing **multiple preprocessed samples into a single file**, we can make further speed gains. 
We distribute the data over **partitions** to facilitate **parallelisation** when the data are used. 
First we need to **define a location** where we want to put the file. 
"""

GCS_OUTPUT = BUCKET + '/tfrecords-jpeg-192x192-2/flowers'  # prefix for output file names

"""Now we can **write the TFRecord files** to the bucket. 

Running the cell takes some time and **only needs to be done once** or not at all, as you can use the publicly available data for the next few cells. For convenience I have commented out the call to `write_tfrecords` at the end of the next cell. You don't need to run it (it takes some time), but you'll need to use the code below later (but there is no need to study it in detail). 

There is a **ready-made pre-processed data** versions available here: 
`gs://flowers-public/tfrecords-jpeg-192x192-2/`, that we can use for testing. 
"""

# functions for writing TFRecord entries
# Feature values are always stored as lists, a single data element will be a list of size 1
def _bytestring_feature(list_of_bytestrings):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))

def _int_feature(list_of_ints): # int64
    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))  

def to_tfrecord(tfrec_filewriter, img_bytes, label): # Create tf data records 
    class_num = np.argmax(np.array(CLASSES)==label) # 'roses' => 2 (order defined in CLASSES)
    one_hot_class = np.eye(len(CLASSES))[class_num]     # [0, 0, 1, 0, 0] for class #2, roses
    feature = {
        "image": _bytestring_feature([img_bytes]), # one image in the list
        "class": _int_feature([class_num]) #,      # one class in the list
    }
    return tf.train.Example(features=tf.train.Features(feature=feature))

def write_tfrecords(GCS_PATTERN,GCS_OUTPUT,partition_size): # write the images to files. 
    print("Writing TFRecords")
    tt0 = time.time()
    filenames = tf.data.Dataset.list_files(GCS_PATTERN) 
    dataset1 = filenames.map(decode_jpeg_and_label)
    dataset2 = dataset1.map(resize_and_crop_image)  
    dataset3 = dataset2.map(recompress_image)
    dataset4 = dataset3.batch(partition_size) # partitioning: there will be one "batch" of images per file 
    for partition, (image, label) in enumerate(dataset4):
        # batch size used as partition size here
        partition_size = image.numpy().shape[0]
        # good practice to have the number of records in the filename
        filename = GCS_OUTPUT + "{:02d}-{}.tfrec".format(partition, partition_size)
        # You need to change GCS_OUTPUT to your own bucket to actually create new files  
        with tf.io.TFRecordWriter(filename) as out_file:
            for i in range(partition_size):
                example = to_tfrecord(out_file,
                                    image.numpy()[i], # re-compressed image: already a byte string
                                    label.numpy()[i] #
                                    )
                out_file.write(example.SerializeToString())
        print("Wrote file {} containing {} records".format(filename, partition_size))
    print("Total time: "+str(time.time()-tt0))

#  write_tfrecords(GCS_PATTERN,GCS_OUTPUT,partition_size) # uncomment to run this cell

"""### Test the TFRecord files

We can now **read from the TFRecord files**. By default, we use the files in the public bucket. Comment out the 1st line of the cell below to use the files written in the cell above.
"""

GCS_OUTPUT = 'gs://flowers-public/tfrecords-jpeg-192x192-2/' 
# remove the line above to use your own files that you generated above

def read_tfrecord(example):
    features = {
        "image": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)
        "class": tf.io.FixedLenFeature([], tf.int64) #,   # shape [] means scalar
    }
    # decode the TFRecord
    example = tf.io.parse_single_example(example, features)
    image = tf.image.decode_jpeg(example['image'], channels=3)
    image = tf.reshape(image, [*TARGET_SIZE, 3])    
    class_num = example['class']
    return image, class_num 

def load_dataset(filenames):
    # read from TFRecords. For optimal performance, read from multiple    
    # TFRecord files at once and set the option experimental_deterministic = False
    # to allow order-altering optimizations.
    option_no_order = tf.data.Options()
    option_no_order.experimental_deterministic = False

    dataset = tf.data.TFRecordDataset(filenames)
    dataset = dataset.with_options(option_no_order)
    dataset = dataset.map(read_tfrecord)
    return dataset

    
filenames = tf.io.gfile.glob(GCS_OUTPUT + "*.tfrec")
datasetTfrec = load_dataset(filenames)

"""Let's have a look **if reading from the TFRecord** files is **quicker**. """

batched_dataset = datasetTfrec.batch(10)
sample_set = batched_dataset.take(10)
for image, label in sample_set: 
    print("Image batch shape {}, {})".format(image.numpy().shape, \
                        [str(lbl) for lbl in label.numpy()]))

"""Wow, we have a **massive speed-up**! The repackageing is worthwhile :-)

## Task 1: Write TFRecord files to the cloud with Spark (40%)

Since recompressing and repackaging is very effective, we would like to be able to do it inparallel for large datasets. 
This is a relatively straightforward case of **parallelisation**. 
We will **use Spark to implement** the same process as above, but in parallel.

### 1a)	Create the script (14%)

**Re-implement** the pre-processing in Spark, using Spark mechanisms for **distributing** the workload **over multiple machines**. 

You need to: 

i) **Copy** over the **mapping functions** (see section 1.1) and **adapt** the resizing and recompression functions **to Spark** (only one argument). (3%)

ii) **Replace** the TensorFlow **Dataset objects with RDDs**, starting with an RDD that contains the list of image filenames. (3%)

iii) **Sample** the the RDD to a smaller number at an appropriate position in the code. Specify a sampling factor of 0.02 for short tests. (1%)

iv) Then **use the functions from above** to write the TFRecord files. (3%)

v) The code for **writing to the TFRecord files** needs to be put into a function, that can be applied to every partition with the ['RDD.mapPartitionsWithIndex'](https://spark.apache.org/docs/2.4.8/api/python/pyspark.html#pyspark.RDD.mapPartitionsWithIndex) function. 
The return value of that function is not used here, but you should return the filename, so that you have a list of the created TFRecord files. (4%)
"""

### CODING TASK ###



# Task1: 1a) Create the script 
# steps in code
# importing libraries and modules
# define the mapping functions get_label, resize, and recompress as before.
# define the function write_tfrecords to write TFRecord files to the cloud using Spark. This function takes an index and an iterator as input, where the iterator contains tuples of filename and image contents. It returns a list of the names of the created TFRecord files.
# initialize Spark by creating a SparkConf and SparkContext, and a SparkSession from the SparkContext.
# load the image filenames into an RDD using sc.binaryFiles.
# sample the RDD to a smaller number using sample.
# preprocess the images and write the TFRecord files using map, mapPartitionsWithIndex, and write_tfrecords.
# collect the list of created TFRecord files using collect.
# print the list of created TFRecord files.



# importing modules and libraries
import os
import tensorflow as tf
import numpy as np
from PIL import Image
from pyspark import SparkConf, SparkContext
from pyspark.sql import SparkSession

# Define mapping functions
def get_label(path):
    """
    Returns the label of an image path.
    """
    return os.path.basename(os.path.dirname(path))

def resize(path, size):
    """
    Resizes an image given its path and a target size.
    Returns the resized image as a NumPy array.
    """
    with Image.open(path) as img:
        img = img.resize(size)
        return np.asarray(img)

def recompress(img, format):
    """
    Recompresses an image given its contents as a NumPy array and a target format.
    Returns the contents of the recompressed image as a byte string.
    """
    with Image.fromarray(img) as img:
        img = img.convert(format)
        with tf.io.BytesIO() as output:
            img.save(output, format=format)
            contents = output.getvalue()
            return contents

# Define function to write TFRecord files
def write_tfrecords(index, iterator):
    """
    Writes TFRecord files given an index and an iterator of (filename, contents) tuples.
    Returns a list of the names of the created TFRecord files.
    """
    tfrecord_files = []
    for i, item in enumerate(iterator):
        filename, contents = item
        if i % 100 == 0:
            print(f'Writing record {i}')
        tfrecord_file = f'flowers_{index}_{i:05d}.tfrecord'
        tfrecord_files.append(tfrecord_file)
        with tf.io.TFRecordWriter(tfrecord_file) as writer:
            example = tf.train.Example(features=tf.train.Features(feature={
                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[contents])),
                'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[get_label(filename).encode('utf-8')]))
            }))
            writer.write(example.SerializeToString())
    return tfrecord_files

# Initialize Spark
conf = SparkConf().setAppName('preprocessing')
sc = SparkContext(conf=conf)
spark = SparkSession(sc)

# Load image filenames into RDD
filenames_rdd = sc.binaryFiles('gs://path/to/flowers/*/*.jpg')

# Sample the RDD
sampled_rdd = filenames_rdd.sample(False, 0.02)

# Preprocess images and write TFRecord files
tfrecord_files_rdd = sampled_rdd.map(lambda x: (x[0], resize(x[1].open(), (180, 180)))).map(lambda x: (x[0], recompress(x[1], 'JPEG'))).mapPartitionsWithIndex(write_tfrecords)

# Collect list of created TFRecord files
tfrecord_files = tfrecord_files_rdd.collect()

# Print list of created TFRecord files
print(tfrecord_files)


"""### 1b)	Testing (3%)

i) Read from the TFRecord Dataset, using `load_dataset` and `display_9_images_from_dataset` to test. 

"""

### CODING TASK ###

"""ii) Write your code above into a file using the *cell magic* `%%writefile spark_write_tfrec.py` at the beginning of the file. Then, run the file  locally in Spark. 


"""
#Answer:

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

# Load the dataset using load_dataset()
dataset = tfds.load('dataset_name', split='train')

# Display 9 images from the dataset
fig = plt.figure(figsize=(10, 10))
for i, example in enumerate(dataset.take(9)):
  # Extract the image and label from the example
  image, label = example['image'], example['label']
  
  # Create a subplot for each image
  ax = fig.add_subplot(3, 3, i+1)
  
  # Remove the x and y ticks from the plot
  ax.set_xticks([])
  ax.set_yticks([])
  
  # Display the image on the plot
  ax.imshow(image.numpy())
  
  # Set the title of the plot to the corresponding label
  ax.set_title(f"Label: {label.numpy()}")

# Show the plot
plt.show()




### CODING TASK ###
gcloud dataproc clusters create my-cluster \
    --num-workers=0 \
    --num-masters=1 \
    --master-machine-type n1-standard-8 \
    --boot-disk-size 100 \
    --image-version=2.0 \
    --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh \
    --metadata 'PIP_PACKAGES=tensorflow==2.4.0'


"""### 1c) Set up a cluster and run the script. (6%)

Following the example from the labs, set up a cluster to run PySpark jobs in the cloud. You need to set up so that TensorFlow is installed on all nodes in the cluster.

#### i) Single machine cluster
Set up a cluster with a single machine using the maximal SSD size (100) and 8 vCPUs. 

Enable **package installation** by passing a flag `--initialization-actions` with argument `gs://goog-dataproc-initialization-actions-$REGION/python/pip-install.sh` (this is a public script that will read metadata to determine which packages to install). 
Then, the **packages are specified** by providing a `--metadata` flag with the argument `PIP_PACKAGES=tensorflow==2.4.0`. 

Note: consider using `PIP_PACKAGES="tensorflow numpy"` or `PIP_PACKAGES=tensorflow` in case an older version of tensorflow is causing issues.

When the cluster is running, run your script to check that it works and keep the output cell output. (3%)
"""

### CODING TASK ###

gcloud dataproc clusters create my-cluster \
    --num-workers=0 \
    --num-masters=1 \
    --master-machine-type n1-standard-8 \
    --boot-disk-size 100 \
    --image-version=2.0 \
    --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh \
    --metadata 'PIP_PACKAGES=tensorflow==2.4.0'

"""Run the script in the cloud and test the output. """

### CODING TASK ###
gcloud dataproc jobs submit pyspark --cluster my-cluster --region ${REGION} --py-files spark_write_tfrec.py -- spark_write_tfrec.py


"""In the free credit tier on Google Cloud, there are normally the following **restrictions** on compute machines:
- max 100GB of *SSD persistent disk*
- max 2000GB of *standard persistent disk* 
- max 8 *vCPU*s
- no GPUs

See [here](https://cloud.google.com/free/docs/gcp-free-tier#free-trial) for details 
The **disks are virtual** disks, where **I/O speed is limited in proportion to the size**, so we should allocate them evenly.
This has mainly an effect on the **time the cluster needs to start**, as we are reading the data mainly from the bucket and we are not writing much to disk at all.

#### ii) Maximal cluster
Use the **largest possible cluster** within these constraints, i.e. **1 master and 7 worker nodes**. 
Each of them with 1 (virtual) CPU. 
The master should get the full *SSD* capacity and the 7 worker nodes should get equal shares of the *standard* disk capacity to maximise throughput. 

Once the cluster is running, test your script. (3%)
"""

### CODING TASK ###
gcloud dataproc clusters create my-maximal-cluster \
    --num-workers=7 \
    --num-masters=1 \
    --master-machine-type n1-standard-8 \
    --worker-machine-type n1-standard-1 \
    --master-boot-disk-size 100 \
    --worker-boot-disk-size 100 \
    --worker-local-ssd-count 0 \
    --image-version=2.0 \
    --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh \
    --metadata 'PIP_PACKAGES=tensorflow==2.4.0'


### CODING TASK ###
gcloud dataproc clusters create my-maximal-cluster \
    --num-workers=7 \
    --num-masters=1 \
    --master-machine-type n1-standard-8 \
    --worker-machine-type n1-standard-1 \
    --master-boot-disk-size 100 \
    --worker-boot-disk-size 100 \
    --worker-local-ssd-count 0 \
    --image-version=2.0 \
    --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh \
    --metadata 'PIP_PACKAGES=tensorflow==2.4.0'

    """_summary_

    Returns:
        _type_: _description_
    """### TASK 1d ###
#from pyspark import SparkContext
#import tensorflow as tf
#sc = SparkContext(appName="SparkTF")
# Set up Spark configuration
#conf = tf.compat.v1.ConfigProto()
#conf.setMaster("yarn")
#conf.setAppName("SparkTF")
#conf.set("spark.executor.memory", "2g")
#conf.set("spark.driver.memory", "2g")
#conf.set("spark.executor.instances", "8")
#conf.set("spark.executor.cores", "1")
# Initialize TensorFlow and Spark context
#sess = tf.compat.v1.Session(config=conf)
#sc._jsc.hadoopConfiguration().set("mapreduce.fileoutputcommitter.algorithm.version", "2")
# Define function to create TFRecords
#def create_tfrecord(data):
# Read input data from file and create RDD
#data_rdd = sc.textFile("gs://<input-bucket>/data.txt").repartition(16)
# Convert RDD to TensorFlow dataset and map to TFRecords
#tf_dataset = tf.data.Dataset.from_tensor_slices(data_rdd.toLocalIterator())
#tf_dataset = tf_dataset.map(create_tfrecord)
# Write TFRecords to output directory
#tf_dataset.write.format("tfrecords").option("recordType", "Example").save("gs://<output-bucket>/tfrecords")


"""### 1d)	Optimisation, experiments, and discussion (17%)

i) Improve parallelisation 

If you implemented a straightfoward version, you will 
**probably** observe that **all the computation** is done on only **two nodes**. 
This can be adressed by using the **second parameter** in the initial call to **parallelize**. 
Make the **suitable change** in the code you have written above and mark it up in comments as `### TASK 1d ###`. 

Demonstrate the difference in cluster utilisation before and after the change based on different parameter values with **screenshots from Google Cloud** and measure the **difference in the processing time**. (6%)

ii) Experiment with cluster configurations.

In addition to the experiments above (using 8 VMs),test your program with 4 machines with double the resources each (2 vCPUs, memory, disk) and 1 machine with eightfold resources. 
Discuss the results in terms of disk I/O and network bandwidth allocation in the cloud. (7%)

iii) Explain the difference between this use of Spark and most standard applications like e.g. in our labs in terms of where the data is stored. What kind of parallelisation approach is used here? (4%)

Write the code below and your answers in the report.

# Section 2: Speed tests

We have seen that **reading from the pre-processed TFRecord files** is **faster** than reading individual image files and decoding on the fly. 
This task is about **measuring this effect** and **parallelizing the tests with PySpark**.

## 2.1 Speed test implementation 

Here is **code for time measurement** to determine the **throughput in images per second**. 
It doesn't render the images but extracts and prints some basic information in order to make sure the image data are read. 
We write the information to the null device for longer measurements `null_file=open("/dev/null", mode='w')`. 
That way it will not clutter our cell output.

We use batches ( `dset2 = dset1.batch(batch_size)` ) and select a number of batches with (`dset3 = dset2.take(batch_number)`). 
Then we  use the `time.time()` to take the **time measurement** and take it multiple times, reading from the same dataset to see if reading speed changes with mutiple readings. 

We then **vary** the size of the batch (`batch_size`) and the number of batches (`batch_number`) and **store the results for different values**. 
Store also the **results for each repetition** over the same dataset (repeat 2 or 3 times).

The speed test should be combined in a **function** `time_configs()` that takes a configuration, i.e. a dataset and arrays of `batch_sizes`, `batch_numbers`, and  `repetitions` (an array of integers starting from 1), as **arguments** and runs the time measurement for each combination of batch_size and batch_number for the requested number of repetitions.
"""

# Here are some useful values for testing your code, use higher values later for actually testing throughput
batch_sizes = [2,4] 
batch_numbers = [3,6] 
repetitions = [1]

def time_configs(dataset, batch_sizes, batch_numbers, repetitions): 
    dims = [len(batch_sizes),len(batch_numbers),len(repetitions)] 
    print(dims) 
    results = np.zeros(dims) 
    params = np.zeros(dims + [3]) 
    print( results.shape ) 
    with open("/dev/null",mode='w') as null_file: # for printing the output without showing it
        tt = time.time() # for overall time taking 
        for bsi,bs in enumerate(batch_sizes): 
            for dsi, ds in enumerate(batch_numbers): 
                batched_dataset = dataset.batch(bs)  
                timing_set = batched_dataset.take(ds) 
                for ri,rep in enumerate(repetitions): 
                    print("bs: {}, ds: {}, rep: {}".format(bs,ds,rep)) 
                    t0 = time.time() 
                    for image, label in timing_set: 
                        #print("Image batch shape {}".format(image.numpy().shape),
                        print("Image batch shape {}, {})".format(image.numpy().shape, 
                            [str(lbl) for lbl in label.numpy()]), null_file)
                    td = time.time() - t0 # duration for reading images
                    results[bsi,dsi,ri] = ( bs * ds) / td 
                    params[bsi,dsi,ri] = [ bs, ds, rep ]
    print("total time: "+str(time.time()-tt))
    return results, params

"""**Let's try this function** with a **small number** of configurations of batch_sizes batch_numbers and repetions, so that we get a set of parameter combinations and corresponding reading speeds.
Try reading from the image files (dataset4) and the TFRecord files (datasetTfrec). 
"""

[res,par] = time_configs(dataset4, batch_sizes, batch_numbers, repetitions)
print(res) 
print(par) 

print("=============")

[res,par] = time_configs(datasetTfrec, batch_sizes, batch_numbers, repetitions)
print(res)
print(par)

"""## Task 2: Parallelising the speed test with Spark in the cloud. (36%)

As an exercise in **Spark programming and optimisation** as well as **performance analysis**, we will now implement the **speed test** with multiple parameters in parallel with Spark. 
Runing multiple tests in parallel would **not be a useful approach on a single machine, but it can be in the cloud** (you will be asked to reason about this later).

### 2a) Create the script (14%)
Your task is now to **port the speed test above to Spark** for running it in the cloud in Dataproc. 
**Adapt the speed testing** as a Spark program that performs the same actions as above, but **with Spark RDDs in a distributed way**. 
The distribution should be such that **each parameter combination (except repetition)** is processed in a separate Spark task.

More specifically: 
*   i) combine the previous cells to have the code to create a dataset and create a list of parameter combinations in an RDD (2%)
*   ii) get a Spark context and  create the dataset and run timing test for each combination in parallel (2%)
*   iii) transform the resulting RDD to the structure \( parameter_combination, images_per_second \) and save these values in an array (2%)
*   iv) create an RDD with all results for each parameter as (parameter_value,images_per_second) and collect the result for each parameter  (2%)
*   v) create an RDD with the average reading speeds for each parameter value and collect the results. Keep associativity in mind when implementing the average. (3%) 
*   vi) write the results to a pickle file in your bucket (2%)
*   vii) Write your code it into a file using the *cell magic* `%%writefile spark_job.py` (1%)


**Important:** The task here is not to parallelize the pre-processing, but to run multiple speed tests in parallel using Spark.
"""

### CODING TASK
import tensorflow as tf
import time

def time_configs(dataset, batch_sizes, batch_numbers, repetitions):
    null_file = open("/dev/null", mode='w')
    results = {}
    for batch_size in batch_sizes:
        for batch_number in batch_numbers:
            dset2 = dataset.batch(batch_size)
            dset3 = dset2.take(batch_number)
            times = []
            for i in range(repetitions):
                start_time = time.time()
                for batch in dset3:
                    images, labels = batch
                    print("batch size:", len(images), "number of batches:", batch_number, file=null_file)
                end_time = time.time()
                times.append(end_time - start_time)
            results[(batch_size, batch_number)] = times
    return results


"""### 2b) Testing the code and collecting results (4%)

i) First, test locally with `%run`.

It is useful to create a **new filename argument**, so that old results don't get overwritten. 

You can for instance use `datetime.datetime.now().strftime("%y%m%d-%H%M")` to get a string with the current date and time and use that in the file name.
"""

### CODING TASK
import tensorflow as tf
import numpy as np
import argparse
import datetime

# Define command-line arguments
parser = argparse.ArgumentParser(description='Convert a set of images to TFRecords.')
parser.add_argument('input_dir', help='Directory containing the input images')
parser.add_argument('output_dir', help='Directory to write the output TFRecords')
parser.add_argument('--num-shards', default=5, type=int, help='Number of TFRecord shards')
parser.add_argument('--file-name', default=datetime.datetime.now().strftime("%y%m%d-%H%M"), help='Name of the output TFRecord file(s)')
args = parser.parse_args()

# Get list of image filenames
image_files = tf.data.Dataset.list_files(args.input_dir + '/*')

# Define function to serialize images and write to TFRecord file
def serialize_image(image_file):
    # Read image from file
    image = tf.io.read_file(image_file)
    # Decode image to a 3D tensor
    image = tf.io.decode_image(image)
    # Convert to 4D tensor with batch size 1
    image = tf.expand_dims(image, 0)
    # Serialize tensor to string
    feature = {
        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(image).numpy()])),
    }
    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
    return example_proto.SerializeToString()

# Create dataset of serialized image data
image_data = image_files.map(serialize_image)

# Create dataset of TFRecord shard filenames
num_shards = args.num_shards
tfrecord_filenames = [args.output_dir + '/' + args.file_name + '-{}.tfrec'.format(i) for i in range(num_shards)]

# Write serialized image data to TFRecord files
for i, filename in enumerate(tfrecord_filenames):
    writer = tf.data.experimental.TFRecordWriter(filename)
    writer.write(image_data.shard(num_shards, i))
    
# Print message when finished
print('Successfully wrote {} images to TFRecord files.'.format(len(image_files)))


"""ii) Cloud

If  you have a cluster running, you can run the  speed test job in the cloud. 

While you run this job, switch to the Dataproc web page and take **screenshots of the CPU and network load** over time. They are displayed with some delay, so you may need to wait a little. These images will be useful in the next task. Again, don't use the SCREENSHOT function that Google provides, but just take a picture of the graphs you see for the VMs. 

"""

### CODING TASK ###
import tensorflow as tf
import datetime
import time

def time_configs(dataset, batch_sizes, batch_numbers, repetitions, filename):
    """Function to run time measurement on combinations of batch_sizes and batch_numbers for each repetition
    and store the results in a file.

    Args:
    - dataset: tf.data.Dataset, the dataset to use for testing
    - batch_sizes: list of integers, the different batch sizes to test
    - batch_numbers: list of integers, the different numbers of batches to test
    - repetitions: list of integers, the number of times to repeat the test with the same dataset
    - filename: str, the name of the file to store the results
    """

    # Open the file for writing
    f = open(filename, 'w')
    
    # Iterate over the different batch sizes and numbers
    for bs in batch_sizes:
        for bn in batch_numbers:
            # Calculate the number of images in the batches
            n_images = bs * bn

            # Iterate over the repetitions
            for r in repetitions:
                # Take a certain number of batches from the dataset
                dset1 = dataset
                dset2 = dset1.batch(bs)
                dset3 = dset2.take(bn)
                
                # Read the images and time it
                start_time = time.time()
                for batch in dset3:
                    null_file=open("/dev/null", mode='w')
                    for image in batch:
                        tf.print(tf.shape(image), output_stream=null_file)
                end_time = time.time()

                # Calculate the elapsed time and the speed in images per second
                elapsed_time = end_time - start_time
                speed = n_images / elapsed_time
                
                # Write the results to the file
                f.write(f"Batch size: {bs}, Batch number: {bn}, Repetition: {r}\n")
                f.write(f"Elapsed time (s): {elapsed_time:.2f}, Speed (images/s): {speed:.2f}\n\n")
    
    # Close the file
    f.close()


"""### 2c) Improve efficiency (6%)

If you implemented a straightfoward version of 2a), you will **probably have an inefficiency** in your code. 

Because we are reading multiple times from an RDD to read the values for the different parameters and their averages, caching existing results is important. Explain **where in the process caching can help**, and **add a call to `RDD.cache()`** to your code, if you haven't yet. Measure the the effect of using caching or not using it.

Make the **suitable change** in the code you have written above and mark them up in comments as `### TASK 2c ###`. 

Explain in your report what the **reasons for this change** are and **demonstrate and interpret its effect**

### 2d) Retrieve, analyse and discuss the output (12%)

Run the tests over a wide range of different paramters and list the results in a table. 

Perform a **linear regression** (e.g. using scikit-learn) over **the values for each parameter** and for the **two cases** (reading from image files/reading TFRecord files). 
List a **table** with the output and interpret the results in terms of the effects of overall.  
Also, **plot** the output values, the averages per parameter value and the regression lines for each parameter and for the product of batch_size and batch_number

Discuss the **implications** of this result for **applications** like large-scale machine learning. 
Keep in mind that cloud data may be stored in distant physical locations. 
Use the numbers provided in the PDF latency-numbers document available on Moodle or [here](https://gist.github.com/hellerbarde/2843375) for your arguments. 

How is the **observed** behaviour **similar or different** from what you’d expect from a **single machine**? Why would cloud providers tie throughput to capacity of disk resources? 

By **parallelising** the speed test we are making **assumptions** about the limits of the bucket reading speeds. 
See [here](https://cloud.google.com/storage/docs/request-rate) for more information.
Discuss, **what we need to consider** in **speed tests** in parallel on the cloud, which bottlenecks we might be identifying, and how this relates to your results. 

Discuss to what extent **linear modelling** reflects the **effects** we are observing. 
Discuss what could be expected from a theoretical perspective and what can be useful in practice.
  
Write your **code below** and **include the output** in your submitted `ipynb` file. Provide the answer **text in your report**.
"""

### CODING TASK ###
gcloud dataproc clusters create my-maximal-cluster \ --num-workers=7 \ --num-masters=1 \ --master-machine-type n1-standard-8 \ --worker-machine-type n1-standard-1 \ --master-boot-disk-size 100 \ --worker-boot-disk-size 100 \ --worker-local-ssd-count 0 \ --image-version=2.0 \ --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh \ --metadata 'PIP_PACKAGES=tensorflow==2.4.0' 

#speedtest.py
import tensorflow as tf
import datetime
import time

def time_configs(dataset, batch_sizes, batch_numbers, repetitions, filename):
    """Function to run time measurement on combinations of batch_sizes and batch_numbers for each repetition
    and store the results in a file.

    Args:
    - dataset: tf.data.Dataset, the dataset to use for testing
    - batch_sizes: list of integers, the different batch sizes to test
    - batch_numbers: list of integers, the different numbers of batches to test
    - repetitions: list of integers, the number of times to repeat the test with the same dataset
    - filename: str, the name of the file to store the results
    """

    # Open the file for writing
    f = open(filename, 'w')
    
    # Iterate over the different batch sizes and numbers
    for bs in batch_sizes:
        for bn in batch_numbers:
            # Calculate the number of images in the batches
            n_images = bs * bn

            # Iterate over the repetitions
            for r in repetitions:
                # Take a certain number of batches from the dataset
                dset1 = dataset
                dset2 = dset1.batch(bs)
                dset3 = dset2.take(bn)
                
                # Read the images and time it
                start_time = time.time()
                for batch in dset3:
                    null_file=open("/dev/null", mode='w')
                    for image in batch:
                        tf.print(tf.shape(image), output_stream=null_file)
                end_time = time.time()

                # Calculate the elapsed time and the speed in images per second
                elapsed_time = end_time - start_time
                speed = n_images / elapsed_time
                
                # Write the results to the file
                f.write(f"Batch size: {bs}, Batch number: {bn}, Repetition: {r}\n")
                f.write(f"Elapsed time (s): {elapsed_time:.2f}, Speed (images/s): {speed:.2f}\n\n")
    
    # Close the file
    f.close()


"""# Section 3. Theoretical discussion

## Task 3: Discussion in context. (24%)

In this task we refer an idea that is introduced in this paper:
-	Alipourfard, O., Liu, H. H., Chen, J., Venkataraman, S., Yu, M., & Zhang, M. (2017). [Cherrypick: Adaptively unearthing the best cloud configurations for big data analytics.](https://people.irisa.fr/Davide.Frey/wp-content/uploads/2018/02/cherrypick.pdf). In USENIX NSDI  17 (pp. 469-482).

Alipourfard et al (2017) introduce  the prediction an optimal or near-optimal cloud configuration for a given compute task. 

### 3a)	Contextualise

Relate the previous tasks and the results to this concept. (It is not necessary to work through the full details of the paper, focus just on the main ideas). To what extent and under what conditions do the concepts and techniques in the paper apply to the task in this coursework? (12%)

### 3b)	Strategise

Define - as far as possible - concrete strategies for different application scenarios (batch, stream) and discuss the general relationship with the concepts above. (12%)

Provide the answers to these questions in your report.

## Final cleanup

Once you have finshed the work, you can delete the buckets, to stop incurring cost that depletes your credit.
"""

!gsutil -m rm -r $BUCKET/* # Empty your bucket 
!gsutil rb $BUCKET # delete the bucket